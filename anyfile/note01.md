---
export_on_save:
 html: true
---
@import "/blog_head.md"

# Python 数据挖掘 (笔记)

> 参考：《Python数据分析与挖掘实战》

## 数据挖掘基础

### 数据挖掘的任务

- 分类
- 回归
- 聚类分析
- 偏差检测
- 时序模式
- 关联规则
- 智能推荐


### 数据挖掘的建模过程

```mermaid
graph LR
    def_aim("定义挖掘目标<br>○ 任务了解<br>○ 指标确定")==>data_collect("数据采集<br>○ 建模抽样<br>○ 质量把控<br>○ 实时采集")
    data_collect==>reorganize("数据整理<br>○ 数据探索<br>○ 数据清洗<br>○ 数据变换")
    reorganize==>construct_model("构建模型<br>○ 模式发现<br>○ 构建模型<br>○ 验证模型")
    construct_model==>model_evaluate("模型评价<br>○ 设定评价标准<br>○ 多模型对比<br>○ 模型优化")
    model_evaluate==>model_release("模型发布<br>○ 模型部署<br>○ 模型重构")
```

```viz
digraph G{
    rankdir=LR
    node [shape=box,fontsize=12]
    A [label="定义挖掘目标\n○ 任务了解\n○ 指标确定"]
    B [label="数据采集\n○ 建模抽样\n○ 质量把控\n○ 实时采集"]
    C [label="数据整理\n○ 数据探索\n○ 数据清洗\n○ 数据变换"]
    D [label="构建模型\n○ 模式发现\n○ 构建模型\n○ 验证模型"]
    E [label="模型评价\n○ 设定评价标准\n○ 多模型对比\n○ 模型优化"]
    F [label="模型发布\n○ 模型部署\n○ 模型重构"]
    A->B->C->D->E->F
}
```

### 定义挖掘目标

需要考虑以下几个问题：
- 本次挖掘的目标是什么？
- 系统完成后要达到什么样的效果？

为了解决这些问题，我们需要分析应用领域，包括应用中的各种知识和应用目标，了解相关领域的情况，熟悉背景知识，弄清用户需求。

### 数据采样

#### 确定采样的数据子集

在明确了数据挖掘的目标后，接下来就是从业务系统中抽取一个与挖掘目标相关的样本数据子集。抽取数据的标准是相关性，可靠性，有效性。通过对数据样本的精选不仅能够减少数据处理量，节省系统资源，还可以使我们想要寻找的规律性更加凸显。

#### 把控采样质量

任何时候都不能忽视数据的质量，即使是一个数据仓库中进行数据采样，也不能忘记检查其质量。因为数据挖掘是要探索某种现象内在的规律，原始数据的错误会导致很难从数据中得到其中的规律性。衡量数据质量的标准：
- 资料完整无缺，各类指标项齐全；
- 数据准确无误，反映的都是正常状态下的水平；

对于获取的数据，可以再从中抽样，抽样的方式很多，常见的有：
- 随机抽样
- 等距抽样
- 分层抽样
- 从起始顺序抽样
- 分类抽样

其中分层抽样得到的抽样结果更加具有代表性，能使模型具有更好的拟合精度；从起始顺序抽样是指抽取从数据起始处开始的连续数据；

### 数据探索

当我们拿到一个样本数据集后，需要注意以下几点：
- 它是否达到我们原来设想的要求？
- 样本中有没有什么明显的规律和趋势？
- 有没有出现从未设想过的数据状态？
- 属性之间有什么相关性？
- 它们可区分成怎样的一些类别？
- ... ...

对所抽取的样本数据进行探索、审核和必要的加工处理是保证最终的挖掘模型的质量所必须的。

机器学习中有一句名言：**数据和特征决定了机器学习的上限，而模型和算法的应用只是让我们不断逼近这个上限** 。这个算法说明了前期数据处理、特征提取的重要性。

数据探索主要包括：异常值分析、缺失值分析、相关分析 和 周期性分析。

### 数据预处理

当采样数据维度过大时，如何进行**降维处理**、**缺失值处理**等都是数据预处理要解决的问题。

由于采样数据中常常包含许多含有噪声、不完整，甚至是不一致的数据，对数据挖掘所涉及的数据对象必须进行预处理。

预处理主要包括以下方式：
- 数据筛选
- 数据变量转换
- 缺失值处理
- 数据标准化
- 主成分分析
- 属性选择
- 数据规约

### 挖掘建模

样本抽取完成并经过预处理后，接下来要考虑的问题是：本次建模属于数据挖掘应用中的哪类问题（分类、回归、聚类、时间模式、智能推荐、关联规则），选用哪种算法进行模型构建？

这一步是数据挖掘工作中的核心环节。

### 模型评价

模型评价的目的之一就是从多个模型中自动找到一个最好的模型，只有好的评估才能对模型的选择、调试具有指导意义。

## Python 数据分析简介

Python 是一门编程语言，这意味着原则上来说，它能够完成Matlab所能做的所有事情，而且在大多数情况下，同样的功能，同样功能的Python代码会比Matlab代码更加简洁易懂。

Python 以开发效率著称，即其致力于以最短的代码完成任务。Python通常为人诟病的是其运行效率，而 Python 还被称为“胶水语言”，它允许我们把耗时的核心部分用 C/C++ 等高效率的语言编写，然后由它进行“粘合”，这很大程度上解决了Python的运行效率问题。事实上，在**大多数数据任务**上，Python 的运行效率已经可以媲美 C/C++ 语言了。

### 数据结构

#### 列表/元组

列表(`list`)和元组(`tuple`)都是序列结构，它们本身很相似，但有有点不同。

从外形上看，列表用方括号标记，如 `a=[1,2,3]`，而元组是用圆括号标记的，如 `b=(4,5,6)`，访问列表和元组中的方式相同，容器中的元素类型没有限制。

列表/元组相关函数：
- `len(a)` : 列表/元组元素的个数
- `max(a)` : 列表/元组元素最大值
- `min(a)` : 列表/元组元素最小值
- `sum(a)` : 列表/元组元素求和
- `sorted(a)` : 对序列进行排序
- `reversed(a)` : 获得序列的反向遍历迭代器

此外，作为对象，列表本身自带了很多实用的方法（元组不允许修改，因此方法很少）：

- `a.append(1)` : 将 1 添加到列表`a`末尾
- `a.insert(2,1)` : 在索引2处插入元素1
- `a.pop(1)` : 移除列表`a`中索引为1的元素，并将该元素返回
- `del a[1]` : 移除列表`a`中索引为1的元素
- `a.count(1)` : 统计列表`a`中元素1出现的次数
- `a.index(1)` : 从列表中找到第一个1的索引位置
- `a.extend([1,2])` : 将列表 `[1,2]` 追加到列表`a`的末尾
- `a+b` : 将 `a` 和 `b` 合并后返回，其本身不变

最后，不得不提的是“列表解析”这一功能，它能够简化我们对列表内元素逐一进行操作的代码，如下面的代码：
```python
a = [1,2,3]
b = []
for i in a:
    b.append(i + 2)

# 上面的代码等价为:
b = [i+2 for i in a]
```
这正体现了Python以最短的代码完成任务的口号！

### 函数式编程

**函数式编程**称为函数程序设计或泛函编程，是一种编程范式，它将计算机运算视为数学上的函数计算，并且避免使用程序状态以及易变对象。简单来讲，函数式编程是一种 “广播式” 的编程，一般结合 lambda 定义函数，用于科学计算中会显得特别简洁方便。

在Python中，函数式编程主要由几个函数的使用构成：`lambda()`、 `map()`、 `reduce()`、 `filter()`。

#### lambda

`lambda` 用于定义行内函数，有点类似于 Matlab 中的“匿名函数”。
```python
f = lambda x : x + 2   # 定义函数 f(x)=x+2
g = lambda x, y: x + y # 定义函数 g(x,y)=x+y
```

#### map

`map` 函数将函数逐一应用到（map）列表中的每个元素，最后返回一个数组。

之前，我们用列表解析完成了将 `a` 中每个元素加2的操作，下面我们用map实现同样的功能：
```python {cmd}
a = [1,2,3]
b = map(lambda x:x+2, a)
print(tuple(b))
```
`map`函数创建了一个待运行的命令容器，在其他函数调用它时返回结果。

> 为什么相同功能的实现可以使用两种不同的语法？
使用列表解析本质上还是要使用`for`循环，而Python的`for`循环命令的效率低，而`map()`函数实现了相同的，并且效率更高，原则上来说，它的循环速度相当于C语言。

**上面的说法值得商榷，通过测试发现，使用列表解析所用的CPU时间稍小于`map`,而使用的系统时间多于`map`,两者之和其实相差非常小，所以建议还是使用列表解析吧。<https://stackoverflow.com/questions/1247486/python-list-comprehension-vs-map> 这个高票答案也说明了map效率并不能提高反而有时会降低，所以还是多用列表解析吧，效率高还可读性好。**

#### filter

`filter()`函数顾名思义就是用于筛选出列表中符合条件的元素，如筛选出数组中所有的偶数：
```python {cmd}
b = filter(lambda x:x%2==0, range(1,20,3))
print(list(b))
```
注意：`filter()`函数传入的第一个函数参数返回值必须是`bool`类型。

上面的代码也可以用列表解析实现：
```python {cmd}
print([x for x in range(1,20,3) if x%2==0])
```



